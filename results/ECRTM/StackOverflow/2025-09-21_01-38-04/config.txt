dataset: StackOverflow
plm_model: all-mpnet-base-v2
model: ECRTM
num_topics: 50
num_groups: 20
dropout: 0.2
hidden_dim_1: 384
hidden_dim_2: 384
theta_temp: 1.0
DT_alpha: 3.0
TW_alpha: 2.0
weight_GR: 1.0
alpha_GR: 5.0
weight_InfoNCE: 50.0
beta_temp: 0.2
weight_ECR: 100.0
use_pretrainWE: True
wandb_prj: topmost
epochs: 500
batch_size: 200
lr: 0.002
device: cpu
seed: 0
lr_scheduler: StepLR
lr_step_size: 125
tune_SVM: False
glove: glove.6B.100d.txt
wete_beta: 0.5
wete_epsilon: 0.1
init_alpha: True
checkpoint_file_path: None
